{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Hyperparameters & locations\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = {'waiting_folder' : '../data/waiting times'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Reading the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waiting_times = list()\n",
    "for attraction in tqdm(os.listdir(locs['waiting_folder'])):\n",
    "    filename = os.path.join(locs['waiting_folder'], attraction)\n",
    "    df = pd.read_csv(filename)\n",
    "    if df.empty:\n",
    "        continue\n",
    "    df.insert(0, 'attraction', attraction.split('.')[0])\n",
    "    waiting_times.append(df)\n",
    "\n",
    "df_wait_raw = pd.concat(waiting_times, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Cleaning the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wait = df_wait_raw.copy()\n",
    "# Cleaning the actual waiting times\n",
    "# Removing outliers from actuals\n",
    "df_wait = df_wait[((df_wait.SACTMIN >= -1000) & (df_wait.SACTMIN < 360)) | (df_wait.SACTMIN.isnull())]\n",
    "# Removing outliers from posted (attraction closed at -999)\n",
    "df_wait = df_wait[(df_wait.SPOSTMIN >= -998.99) | (df_wait.SPOSTMIN.isnull())]\n",
    "\n",
    "df_wait['date'] = pd.to_datetime(df_wait.date, format = '%m/%d/%Y')\n",
    "df_wait['datetime'] = pd.to_datetime(df_wait.datetime, format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(f\"Removed {len(df_wait_raw) - len(df_wait)} rows\")\n",
    "\n",
    "# You could split the dataset into two seperate dataframes (plusjes & minnetjes :-))\n",
    "df_wait_act = df_wait[~df_wait.SACTMIN.isnull()].drop('SPOSTMIN', axis = 1)\n",
    "df_wait_post = df_wait[~df_wait.SPOSTMIN.isnull()].drop('SACTMIN', axis = 1)\n",
    "\n",
    "attractions = df_wait.attraction.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract \"minutes from df_wait\" from the datetime column\n",
    "df_wait_post['minute'] = df_wait_post['datetime'].dt.hour * 60 + df_wait_post['datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wait_post['attraction'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    SPOSTMIN Resampling index to every 30 mins with interpolation\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code starts from the posted waiting times. \n",
    "# Reindex and resample to a datapoint every 30 minutes. \n",
    "# Add leading zeros and fill gaps with interpolated values.\n",
    "\n",
    "groups_post = list()\n",
    "\n",
    "for (date, attraction), group in tqdm(df_wait_post.groupby(['date', 'attraction'])):\n",
    "    # Time shift by 3 hours\n",
    "    time_shifted = group['datetime'] - datetime.timedelta(hours=3)\n",
    "    group['minute'] = 3 * 60 + time_shifted.dt.hour * 60 + time_shifted.dt.minute\n",
    "\n",
    "    # Drop unnecessary columns and compute the mean for duplicate minutes\n",
    "    group = group.drop(columns=['datetime', 'attraction', 'date'], errors='ignore')  # Avoid KeyError\n",
    "    group = group.groupby('minute', as_index=False)[['SPOSTMIN']].mean()\n",
    "\n",
    "    # Define the new index (0 to 1620 minutes in 30-minute intervals)\n",
    "    new_index = np.arange(0, 27 * 60 + 1, 30)\n",
    "\n",
    "    # Set 'minute' as the index and reindex with interpolation\n",
    "    group = group.set_index('minute')\n",
    "    reindexed = group.reindex(np.unique(np.concatenate([new_index, group.index]))).interpolate(method='linear')\n",
    "\n",
    "    # Keep only the required time indices\n",
    "    resampled = reindexed.loc[new_index].reset_index()\n",
    "\n",
    "    # Round to nearest 5-minute interval\n",
    "    resampled['SPOSTMIN'] = resampled['SPOSTMIN'].fillna(0)\n",
    "    resampled['SPOSTMIN'] = (resampled['SPOSTMIN'] + 2.5) // 5 * 5\n",
    "\n",
    "    # Insert date and attraction columns\n",
    "    resampled.insert(0, 'date', date)\n",
    "    resampled.insert(0, 'attraction', attraction)\n",
    "\n",
    "    # Append to final list\n",
    "    groups_post.append(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "df_post_itp = pd.concat(groups_post, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_itp.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset with interpolates posted times to csv\n",
    "df_post_itp.to_csv(\"../data/clean/posted_interpolated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    SACTMIN timeshift for minute column. No resampling or interpolation\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code starts from the actual waiting times.\n",
    "# Apply a time shift to get the minute column similar to the dataset with posted waiting times.\n",
    "\n",
    "groups_act = list()\n",
    "\n",
    "for (date, attraction), group in tqdm(df_wait_act.groupby(['date', 'attraction'])):\n",
    "    # Time shift by 3 hours\n",
    "    time_shifted = group['datetime'] - datetime.timedelta(hours=3)\n",
    "    group['minute'] = 3 * 60 + time_shifted.dt.hour * 60 + time_shifted.dt.minute\n",
    "\n",
    "    # Append to final list\n",
    "    groups_act.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_act_timeshift = pd.concat(groups_act, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_act_timeshift.drop(columns = ['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe dataset with timeshifted actuals to csv\n",
    "df_act_timeshift.to_csv(\"../data/clean/actuals_shifted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Interpolating and preparing training dataframe\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code starts from the entire dataset of posted and actual waiting times.\n",
    "# For every row where there is an actual value, interpolate the posted waiting time.\n",
    "# Calculate the actual-over-posted ratio and prepare the training dataset.\n",
    "\n",
    "groups = list()\n",
    "\n",
    "for (date, attraction), group in tqdm(list(df_wait.groupby(['date', 'attraction']))):\n",
    "    time_shifted = group.datetime - datetime.timedelta(hours = 3)\n",
    "    group['minute'] = 3 * 60 + time_shifted.dt.hour * 60 + time_shifted.dt.minute\n",
    "\n",
    "    # Reindex the DataFrame\n",
    "    # Set the 'minute' column as the index\n",
    "    group = group.set_index('minute')\n",
    "\n",
    "    # Interpolate SPOSTMIN to fill blanks\n",
    "    group['SPOSTMIN_interp'] = group['SPOSTMIN'].interpolate(method='linear')\n",
    "\n",
    "    # Calculate the actual over posted ratio\n",
    "    group['actual_over_posted'] =  group['SACTMIN'] / group['SPOSTMIN_interp']\n",
    "\n",
    "    # Keep only the features and targets for training\n",
    "    group = group.drop(columns=['datetime', 'SACTMIN', 'SPOSTMIN', 'SPOSTMIN_interp']).dropna(subset=['actual_over_posted'])\n",
    "\n",
    "    groups.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "training_dataset = pd.concat(groups, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training dataset to csv\n",
    "training_dataset.to_csv(\"../data/clean/training_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
