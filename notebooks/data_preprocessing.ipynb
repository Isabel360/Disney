{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Hyperparameters & locations\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = {'waiting_folder' : '../data/waiting times'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Reading the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waiting_times = list()\n",
    "for attraction in tqdm(os.listdir(locs['waiting_folder'])):\n",
    "    filename = os.path.join(locs['waiting_folder'], attraction)\n",
    "    df = pd.read_csv(filename)\n",
    "    if df.empty:\n",
    "        continue\n",
    "    df.insert(0, 'attraction', attraction.split('.')[0])\n",
    "    waiting_times.append(df)\n",
    "\n",
    "df_wait_raw = pd.concat(waiting_times, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Cleaning the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wait = df_wait_raw.copy()\n",
    "# Cleaning the actual waiting times\n",
    "# Removing outliers from actuals\n",
    "df_wait = df_wait[((df_wait.SACTMIN >= -1000) & (df_wait.SACTMIN < 360)) | (df_wait.SACTMIN.isnull())]\n",
    "# Removing outliers from posted (attraction closed at -999)\n",
    "df_wait = df_wait[(df_wait.SPOSTMIN >= -998.99) | (df_wait.SPOSTMIN.isnull())]\n",
    "\n",
    "df_wait['date'] = pd.to_datetime(df_wait.date, format = '%m/%d/%Y')\n",
    "df_wait['datetime'] = pd.to_datetime(df_wait.datetime, format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(f\"Removed {len(df_wait_raw) - len(df_wait)} rows\")\n",
    "\n",
    "# You could split the dataset into two seperate dataframes (plusjes & minnetjes :-))\n",
    "df_wait_act = df_wait[~df_wait.SACTMIN.isnull()].drop('SPOSTMIN', axis = 1)\n",
    "df_wait_post = df_wait[~df_wait.SPOSTMIN.isnull()].drop('SACTMIN', axis = 1)\n",
    "\n",
    "attractions = df_wait.attraction.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract \"minutes from df_wait\" from the datetime column\n",
    "df_wait_post['minute'] = df_wait_post['datetime'].dt.hour * 60 + df_wait_post['datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wait_post['attraction'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Preprocessing - timeshift only\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Posted waiting times only\n",
    "# from tqdm import tqdm\n",
    "# groups = list()\n",
    "# for (date, attraction), group in tqdm(df_wait_post.groupby(['date', 'attraction'])):\n",
    "# #for date, group in tqdm(list(df_wait_post.groupby('date'))):\n",
    "#     time_shifted = group.datetime - datetime.timedelta(hours = 3)\n",
    "#     group['minute'] = 3 * 60 + time_shifted.dt.hour * 60 + time_shifted.dt.minute\n",
    "\n",
    "#     # Average out duplicate minutes\n",
    "#     group = group.drop(['datetime', 'attraction', 'date'], axis = 1).groupby(['minute'])['SPOSTMIN'].mean().reset_index()\n",
    "\n",
    "#     new_index = np.arange(0, 27 * 60 + 1, 30)  # Range from 0 to 1620 with a step of 30\n",
    "\n",
    "#     # Step 2: Reindex the DataFrame\n",
    "#     # Set the 'minute' column as the index\n",
    "#     group = group.set_index('minute')\n",
    "\n",
    "#     # Step 3: Reindex to the new index and interpolate\n",
    "#     resampled = group.reindex(np.unique(np.concatenate([new_index, group.index]))).interpolate(method='linear')\n",
    "#     resampled = resampled.loc[new_index]\n",
    "\n",
    "#     # Step 4: Add zeros at the endpoints\n",
    "#     #resampled.loc[0] = 0  # Set the first value to zero\n",
    "#     #resampled.loc[1620] = 0  # Set the last value to zero\n",
    "\n",
    "#     # Step 5: Reset index if needed\n",
    "#     resampled = resampled.reset_index()\n",
    "\n",
    "#     resampled['SPOSTMIN'] = resampled['SPOSTMIN'].fillna(0)\n",
    "#     resampled['SPOSTMIN'] = (resampled['SPOSTMIN'] + 2.5) // 5 * 5\n",
    "#     resampled.insert(0, 'date', date)\n",
    "#     resampled.insert(0, 'attraction', attraction)\n",
    "#     groups.append(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_netjes = pd.concat(groups, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "# df_netjes.to_csv('dataset_Disney_clean_posted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Actual waiting times only\n",
    "# from tqdm import tqdm\n",
    "# groups2 = list()\n",
    "# for (date, attraction), group in tqdm(df_wait_act.groupby(['date', 'attraction'])):\n",
    "# #for date, group in tqdm(list(df_wait_post.groupby('date'))):\n",
    "#     time_shifted = group.datetime - datetime.timedelta(hours = 3)\n",
    "#     group['minute'] = 3 * 60 + time_shifted.dt.hour * 60 + time_shifted.dt.minute\n",
    "\n",
    "#     # Average out duplicate minutes\n",
    "#     group = group.drop(['datetime', 'attraction', 'date'], axis = 1).groupby(['minute'])['SACTMIN'].mean().reset_index()\n",
    "\n",
    "#     new_index = np.arange(0, 27 * 60 + 1, 30)  # Range from 0 to 1620 with a step of 30\n",
    "\n",
    "#     # Step 2: Reindex the DataFrame\n",
    "#     # Set the 'minute' column as the index\n",
    "#     group = group.set_index('minute')\n",
    "\n",
    "#     # Step 3: Reindex to the new index and interpolate\n",
    "#     resampled = group.reindex(np.unique(np.concatenate([new_index, group.index]))).interpolate(method='linear')\n",
    "#     resampled = resampled.loc[new_index]\n",
    "\n",
    "#     # Step 4: Add zeros at the endpoints\n",
    "#     #resampled.loc[0] = 0  # Set the first value to zero\n",
    "#     #resampled.loc[1620] = 0  # Set the last value to zero\n",
    "\n",
    "#     # Step 5: Reset index if needed\n",
    "#     resampled = resampled.reset_index()\n",
    "\n",
    "#     resampled['SACTMIN'] = resampled['SACTMIN'].fillna(0)\n",
    "#     resampled['SACTMIN'] = (resampled['SACTMIN'] + 2.5) // 5 * 5\n",
    "#     resampled.insert(0, 'date', date)\n",
    "#     resampled.insert(0, 'attraction', attraction)\n",
    "#     groups2.append(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_netjes_2 = pd.concat(groups, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_netjes_2.to_csv('dataset_Disney_clean_actuals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Posted and actual waiting times\n",
    "\n",
    "# groups3 = list()\n",
    "\n",
    "# for (date, attraction), group in tqdm(df_wait.groupby(['date', 'attraction'])):\n",
    "#     # Time shift by 3 hours\n",
    "#     time_shifted = group['datetime'] - datetime.timedelta(hours=3)\n",
    "#     group['minute'] = 3 * 60 + time_shifted.dt.hour * 60 + time_shifted.dt.minute\n",
    "\n",
    "#     # Ensure the required columns exist before proceeding\n",
    "#     if not {'SACTMIN', 'SPOSTMIN'}.issubset(group.columns):\n",
    "#         print(f\"Skipping {date} - {attraction}: Missing columns\")\n",
    "#         continue  # Skip this iteration if columns are missing\n",
    "\n",
    "#     # Drop unnecessary columns and compute the mean for duplicate minutes\n",
    "#     group = group.drop(columns=['datetime', 'attraction', 'date'], errors='ignore')  # Avoid KeyError\n",
    "#     group = group.groupby('minute', as_index=False)[['SACTMIN', 'SPOSTMIN']].mean()\n",
    "\n",
    "#     # Define the new index (0 to 1620 minutes in 30-minute intervals)\n",
    "#     new_index = np.arange(0, 27 * 60 + 1, 30)\n",
    "\n",
    "#     # Set 'minute' as the index and reindex with interpolation\n",
    "#     group = group.set_index('minute')\n",
    "#     reindexed = group.reindex(np.unique(np.concatenate([new_index, group.index]))).interpolate(method='linear')\n",
    "\n",
    "#     # Keep only the required time indices\n",
    "#     resampled = reindexed.loc[new_index].reset_index()\n",
    "\n",
    "#     # Fill NaN values with 0 and round to nearest 5-minute interval\n",
    "#     for col in ['SACTMIN', 'SPOSTMIN']:\n",
    "#         if col in resampled.columns:\n",
    "#             resampled[col] = resampled[col].fillna(0)\n",
    "#             resampled[col] = ((resampled[col] + 2.5) // 5) * 5\n",
    "\n",
    "#     # Insert date and attraction columns\n",
    "#     resampled.insert(0, 'date', date)\n",
    "#     resampled.insert(1, 'attraction', attraction)\n",
    "\n",
    "#     # Append to final list\n",
    "#     groups3.append(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_netjes_3 = pd.concat(groups3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_netjes_3.to_csv('dataset_Disney_clean_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Interpolating and preparing training dataframe\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_itp = list()\n",
    "\n",
    "for (date, attraction), group in tqdm(df_wait.groupby(['date', 'attraction'])):\n",
    "    # Time shift by 3 hours\n",
    "    time_shifted = group['datetime'] - datetime.timedelta(hours=3)\n",
    "    group['minute'] = 3 * 60 + time_shifted.dt.hour * 60 + time_shifted.dt.minute\n",
    "\n",
    "    # Ensure the required columns exist before proceeding\n",
    "    if not {'SACTMIN', 'SPOSTMIN'}.issubset(group.columns):\n",
    "        print(f\"Skipping {date} - {attraction}: Missing columns\")\n",
    "        continue  # Skip this iteration if columns are missing\n",
    "\n",
    "    # Drop unnecessary columns and compute the mean for duplicate minutes\n",
    "    group = group.drop(columns=['datetime', 'attraction', 'date'], errors='ignore')  # Avoid KeyError\n",
    "    group = group.groupby('minute', as_index=False)[['SACTMIN', 'SPOSTMIN']].mean()\n",
    "\n",
    "    # Define the new index (0 to 1620 minutes in 30-minute intervals)\n",
    "    new_index = np.arange(0, 27 * 60 + 1, 30)\n",
    "\n",
    "    # Set 'minute' as the index and reindex with interpolation\n",
    "    group = group.set_index('minute')\n",
    "    reindexed = group.reindex(np.unique(np.concatenate([new_index, group.index]))).interpolate(method='linear')\n",
    "\n",
    "    # Keep only the required time indices\n",
    "    resampled = reindexed.loc[new_index].reset_index()\n",
    "\n",
    "    # Round to nearest 5-minute interval\n",
    "    for col in ['SACTMIN', 'SPOSTMIN']:\n",
    "        if col in resampled.columns:\n",
    "            resampled[col] = ((resampled[col] + 2.5) // 5) * 5\n",
    "    \n",
    "    # Interpolate SPOSTMIN to fill blanks\n",
    "    resampled['SPOSTMIN_interp'] = resampled['SPOSTMIN'].interpolate(method='linear')\n",
    "\n",
    "    # Calculate the actual over posted ratio\n",
    "    resampled['actual_over_posted'] =  resampled['SACTMIN'] / resampled['SPOSTMIN_interp']\n",
    "\n",
    "    # Insert date and attraction columns\n",
    "    resampled.insert(0, 'date', date)\n",
    "    resampled.insert(1, 'attraction', attraction)\n",
    "\n",
    "    # Append to final list\n",
    "    groups_itp.append(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netjes_itp = pd.concat(groups_itp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netjes_itp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the full cleaned and interpolated dataset to csv\n",
    "df_netjes_itp.to_csv(\"../data/clean/waiting_times_interpolated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dataset for training our prediction model and save it to csv\n",
    "# Drop unnecessary columns and rows without actual_over_posted ratio\n",
    "training_dataset = df_netjes_itp.drop(columns=['SACTMIN', 'SPOSTMIN', 'SPOSTMIN_interp']).dropna(subset=['actual_over_posted'])\n",
    "\n",
    "training_dataset.to_csv(\"../data/clean/training_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
