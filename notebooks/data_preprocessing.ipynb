{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Hyperparameters & locations\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = {'waiting_folder' : '../data/waiting times'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Reading the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:06<00:00,  7.81it/s]\n"
     ]
    }
   ],
   "source": [
    "waiting_times = list()\n",
    "for attraction in tqdm(os.listdir(locs['waiting_folder'])):\n",
    "    filename = os.path.join(locs['waiting_folder'], attraction)\n",
    "    df = pd.read_csv(filename)\n",
    "    if df.empty:\n",
    "        continue\n",
    "    df.insert(0, 'attraction', attraction.split('.')[0])\n",
    "    waiting_times.append(df)\n",
    "\n",
    "df_wait_raw = pd.concat(waiting_times, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Cleaning the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1318703 rows\n"
     ]
    }
   ],
   "source": [
    "df_wait = df_wait_raw.copy()\n",
    "# Cleaning the actual waiting times\n",
    "# Removing outliers from actuals\n",
    "df_wait = df_wait[((df_wait.SACTMIN >= -1000) & (df_wait.SACTMIN < 360)) | (df_wait.SACTMIN.isnull())]\n",
    "# Removing outliers from posted (attraction closed at -999)\n",
    "df_wait = df_wait[(df_wait.SPOSTMIN >= -998.99) | (df_wait.SPOSTMIN.isnull())]\n",
    "\n",
    "df_wait['date'] = pd.to_datetime(df_wait.date, format = '%m/%d/%Y')\n",
    "df_wait['datetime'] = pd.to_datetime(df_wait.datetime, format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(f\"Removed {len(df_wait_raw) - len(df_wait)} rows\")\n",
    "\n",
    "# You could split the dataset into two seperate dataframes (plusjes & minnetjes :-))\n",
    "df_wait_act = df_wait[~df_wait.SACTMIN.isnull()].drop('SPOSTMIN', axis = 1)\n",
    "df_wait_post = df_wait[~df_wait.SPOSTMIN.isnull()].drop('SACTMIN', axis = 1)\n",
    "\n",
    "attractions = df_wait.attraction.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract \"minutes from df_wait\" from the datetime column\n",
    "df_wait_post['minute'] = df_wait_post['datetime'].dt.hour * 60 + df_wait_post['datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['7_dwarfs_train', 'alien_saucers', 'astro_orbiter', 'barnstormer',\n",
       "       'big_thunder_mtn', 'buzz_lightyear', 'carousel_of_progress',\n",
       "       'country_bears', 'dinosaur', 'dumbo', 'enchanted_tiki_rm',\n",
       "       'expedition_everest', 'flight_of_passage', 'hall_of_presidents',\n",
       "       'haunted_mansion', 'it_s_a_small_world', 'jungle_cruise',\n",
       "       'kilimanjaro_safaris', 'laugh_floor', 'liberty_sq_riverboat',\n",
       "       'mad_tea_party', 'magic_carpets', 'navi_river', 'peoplemover',\n",
       "       'peter_pan_s_flight', 'philharmagic', 'pirates_of_caribbean',\n",
       "       'pirate_s_adventure', 'princess_hall__cinderella_elena',\n",
       "       'princess_hall__rapunzel_tiana', 'regal_carrousel',\n",
       "       'rock_n_rollercoaster', 'slinky_dog', 'soarin',\n",
       "       'sorcerers_of_the_mk', 'spaceship_earth', 'space_mountain',\n",
       "       'splash_mountain', 'swiss_family_tree', 'tom_land_speedway',\n",
       "       'tom_sawyer_island', 'town_sq_mickey', 'toy_story_mania',\n",
       "       'under_the_sea', 'winnie_the_pooh'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wait_post['attraction'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2335/2335 [00:11<00:00, 210.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "groups = list()\n",
    "for date, group in tqdm(list(df_wait_post.groupby('date'))):\n",
    "    time_shifted = group.datetime - datetime.timedelta(hours = 3)\n",
    "    group['minute'] = 3 * 60 + time_shifted.dt.hour * 60 + time_shifted.dt.minute\n",
    "\n",
    "    # Average out duplicate minutes\n",
    "    group = group.drop(['datetime', 'attraction', 'date'], axis = 1).groupby(['minute'])['SPOSTMIN'].mean().reset_index()\n",
    "\n",
    "    new_index = np.arange(0, 27 * 60 + 1, 30)  # Range from 0 to 1620 with a step of 30\n",
    "\n",
    "    # Step 2: Reindex the DataFrame\n",
    "    # Set the 'minute' column as the index\n",
    "    group = group.set_index('minute')\n",
    "\n",
    "    # Step 3: Reindex to the new index and interpolate\n",
    "    resampled = group.reindex(np.unique(np.concatenate([new_index, group.index]))).interpolate(method='linear')\n",
    "    resampled = resampled.loc[new_index]\n",
    "\n",
    "    # Step 4: Add zeros at the endpoints\n",
    "    #resampled.loc[0] = 0  # Set the first value to zero\n",
    "    #resampled.loc[1620] = 0  # Set the last value to zero\n",
    "\n",
    "    # Step 5: Reset index if needed\n",
    "    resampled = resampled.reset_index()\n",
    "\n",
    "    resampled['SPOSTMIN'] = resampled['SPOSTMIN'].fillna(0)\n",
    "    resampled['SPOSTMIN'] = (resampled['SPOSTMIN'] + 2.5) // 5 * 5\n",
    "    resampled.insert(0, 'date', date)\n",
    "    resampled.insert(0, 'attraction', attraction)\n",
    "    groups.append(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netjes = pd.concat(groups, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netjes.to_csv('dataset_Disney_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
