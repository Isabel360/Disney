{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Hyperparameters & locations\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = {'waiting_folder' : '../data/waiting times'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Reading the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:14<00:00,  3.62it/s]\n"
     ]
    }
   ],
   "source": [
    "waiting_times = list()\n",
    "for attraction in tqdm(os.listdir(locs['waiting_folder'])):\n",
    "    filename = os.path.join(locs['waiting_folder'], attraction)\n",
    "    df = pd.read_csv(filename)\n",
    "    if df.empty:\n",
    "        continue\n",
    "    df.insert(0, 'attraction', attraction.split('.')[0])\n",
    "    waiting_times.append(df)\n",
    "\n",
    "df_wait_raw = pd.concat(waiting_times, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Cleaning the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1318703 rows\n"
     ]
    }
   ],
   "source": [
    "df_wait = df_wait_raw.copy()\n",
    "# Cleaning the actual waiting times\n",
    "# Removing outliers from actuals\n",
    "df_wait = df_wait[((df_wait.SACTMIN >= -1000) & (df_wait.SACTMIN < 360)) | (df_wait.SACTMIN.isnull())]\n",
    "# Removing outliers from posted (attraction closed at -999)\n",
    "df_wait = df_wait[(df_wait.SPOSTMIN >= -998.99) | (df_wait.SPOSTMIN.isnull())]\n",
    "\n",
    "df_wait['date'] = pd.to_datetime(df_wait.date, format = '%m/%d/%Y')\n",
    "df_wait['datetime'] = pd.to_datetime(df_wait.datetime, format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(f\"Removed {len(df_wait_raw) - len(df_wait)} rows\")\n",
    "\n",
    "# You could split the dataset into two seperate dataframes (plusjes & minnetjes :-))\n",
    "df_wait_act = df_wait[~df_wait.SACTMIN.isnull()].drop('SPOSTMIN', axis = 1)\n",
    "df_wait_post = df_wait[~df_wait.SPOSTMIN.isnull()].drop('SACTMIN', axis = 1)\n",
    "\n",
    "attractions = df_wait.attraction.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract \"minutes from df_wait\" from the datetime column\n",
    "df_wait_post['minute'] = df_wait_post['datetime'].dt.hour * 60 + df_wait_post['datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['country_bears', '7_dwarfs_train', 'pirates_of_caribbean',\n",
       "       'astro_orbiter', 'laugh_floor', 'regal_carrousel',\n",
       "       'big_thunder_mtn', 'spaceship_earth', 'splash_mountain',\n",
       "       'hall_of_presidents', 'toy_story_mania', 'space_mountain',\n",
       "       'sorcerers_of_the_mk', 'jungle_cruise', 'mad_tea_party',\n",
       "       'princess_hall__cinderella_elena', 'dumbo', 'tom_land_speedway',\n",
       "       'swiss_family_tree', 'magic_carpets', 'tom_sawyer_island',\n",
       "       'soarin', 'peoplemover', 'philharmagic', 'it_s_a_small_world',\n",
       "       'kilimanjaro_safaris', 'expedition_everest', 'town_sq_mickey',\n",
       "       'rock_n_rollercoaster', 'carousel_of_progress', 'under_the_sea',\n",
       "       'dinosaur', 'barnstormer', 'flight_of_passage', 'winnie_the_pooh',\n",
       "       'navi_river', 'enchanted_tiki_rm', 'princess_hall__rapunzel_tiana',\n",
       "       'pirate_s_adventure', 'liberty_sq_riverboat', 'peter_pan_s_flight',\n",
       "       'haunted_mansion', 'alien_saucers', 'buzz_lightyear', 'slinky_dog'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wait_post['attraction'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Preprocessing - timeshift only\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Posted waiting times only\n",
    "# from tqdm import tqdm\n",
    "# groups = list()\n",
    "# for (date, attraction), group in tqdm(df_wait_post.groupby(['date', 'attraction'])):\n",
    "# #for date, group in tqdm(list(df_wait_post.groupby('date'))):\n",
    "#     time_shifted = group.datetime - datetime.timedelta(hours = 3)\n",
    "#     group['minute'] = 3 * 60 + time_shifted.dt.hour * 60 + time_shifted.dt.minute\n",
    "\n",
    "#     # Average out duplicate minutes\n",
    "#     group = group.drop(['datetime', 'attraction', 'date'], axis = 1).groupby(['minute'])['SPOSTMIN'].mean().reset_index()\n",
    "\n",
    "#     new_index = np.arange(0, 27 * 60 + 1, 30)  # Range from 0 to 1620 with a step of 30\n",
    "\n",
    "#     # Step 2: Reindex the DataFrame\n",
    "#     # Set the 'minute' column as the index\n",
    "#     group = group.set_index('minute')\n",
    "\n",
    "#     # Step 3: Reindex to the new index and interpolate\n",
    "#     resampled = group.reindex(np.unique(np.concatenate([new_index, group.index]))).interpolate(method='linear')\n",
    "#     resampled = resampled.loc[new_index]\n",
    "\n",
    "#     # Step 4: Add zeros at the endpoints\n",
    "#     #resampled.loc[0] = 0  # Set the first value to zero\n",
    "#     #resampled.loc[1620] = 0  # Set the last value to zero\n",
    "\n",
    "#     # Step 5: Reset index if needed\n",
    "#     resampled = resampled.reset_index()\n",
    "\n",
    "#     resampled['SPOSTMIN'] = resampled['SPOSTMIN'].fillna(0)\n",
    "#     resampled['SPOSTMIN'] = (resampled['SPOSTMIN'] + 2.5) // 5 * 5\n",
    "#     resampled.insert(0, 'date', date)\n",
    "#     resampled.insert(0, 'attraction', attraction)\n",
    "#     groups.append(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_netjes = pd.concat(groups, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_netjes.to_csv('dataset_Disney_clean_posted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Actual waiting times only\n",
    "# from tqdm import tqdm\n",
    "# groups2 = list()\n",
    "# for (date, attraction), group in tqdm(df_wait_act.groupby(['date', 'attraction'])):\n",
    "# #for date, group in tqdm(list(df_wait_post.groupby('date'))):\n",
    "#     time_shifted = group.datetime - datetime.timedelta(hours = 3)\n",
    "#     group['minute'] = 3 * 60 + time_shifted.dt.hour * 60 + time_shifted.dt.minute\n",
    "\n",
    "#     # Average out duplicate minutes\n",
    "#     group = group.drop(['datetime', 'attraction', 'date'], axis = 1).groupby(['minute'])['SACTMIN'].mean().reset_index()\n",
    "\n",
    "#     new_index = np.arange(0, 27 * 60 + 1, 30)  # Range from 0 to 1620 with a step of 30\n",
    "\n",
    "#     # Step 2: Reindex the DataFrame\n",
    "#     # Set the 'minute' column as the index\n",
    "#     group = group.set_index('minute')\n",
    "\n",
    "#     # Step 3: Reindex to the new index and interpolate\n",
    "#     resampled = group.reindex(np.unique(np.concatenate([new_index, group.index]))).interpolate(method='linear')\n",
    "#     resampled = resampled.loc[new_index]\n",
    "\n",
    "#     # Step 4: Add zeros at the endpoints\n",
    "#     #resampled.loc[0] = 0  # Set the first value to zero\n",
    "#     #resampled.loc[1620] = 0  # Set the last value to zero\n",
    "\n",
    "#     # Step 5: Reset index if needed\n",
    "#     resampled = resampled.reset_index()\n",
    "\n",
    "#     resampled['SACTMIN'] = resampled['SACTMIN'].fillna(0)\n",
    "#     resampled['SACTMIN'] = (resampled['SACTMIN'] + 2.5) // 5 * 5\n",
    "#     resampled.insert(0, 'date', date)\n",
    "#     resampled.insert(0, 'attraction', attraction)\n",
    "#     groups2.append(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_netjes_2 = pd.concat(groups, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_netjes_2.to_csv('dataset_Disney_clean_actuals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Posted and actual waiting times\n",
    "\n",
    "# groups3 = list()\n",
    "\n",
    "# for (date, attraction), group in tqdm(df_wait.groupby(['date', 'attraction'])):\n",
    "#     # Time shift by 3 hours\n",
    "#     time_shifted = group['datetime'] - datetime.timedelta(hours=3)\n",
    "#     group['minute'] = 3 * 60 + time_shifted.dt.hour * 60 + time_shifted.dt.minute\n",
    "\n",
    "#     # Ensure the required columns exist before proceeding\n",
    "#     if not {'SACTMIN', 'SPOSTMIN'}.issubset(group.columns):\n",
    "#         print(f\"Skipping {date} - {attraction}: Missing columns\")\n",
    "#         continue  # Skip this iteration if columns are missing\n",
    "\n",
    "#     # Drop unnecessary columns and compute the mean for duplicate minutes\n",
    "#     group = group.drop(columns=['datetime', 'attraction', 'date'], errors='ignore')  # Avoid KeyError\n",
    "#     group = group.groupby('minute', as_index=False)[['SACTMIN', 'SPOSTMIN']].mean()\n",
    "\n",
    "#     # Define the new index (0 to 1620 minutes in 30-minute intervals)\n",
    "#     new_index = np.arange(0, 27 * 60 + 1, 30)\n",
    "\n",
    "#     # Set 'minute' as the index and reindex with interpolation\n",
    "#     group = group.set_index('minute')\n",
    "#     reindexed = group.reindex(np.unique(np.concatenate([new_index, group.index]))).interpolate(method='linear')\n",
    "\n",
    "#     # Keep only the required time indices\n",
    "#     resampled = reindexed.loc[new_index].reset_index()\n",
    "\n",
    "#     # Fill NaN values with 0 and round to nearest 5-minute interval\n",
    "#     for col in ['SACTMIN', 'SPOSTMIN']:\n",
    "#         if col in resampled.columns:\n",
    "#             resampled[col] = resampled[col].fillna(0)\n",
    "#             resampled[col] = ((resampled[col] + 2.5) // 5) * 5\n",
    "\n",
    "#     # Insert date and attraction columns\n",
    "#     resampled.insert(0, 'date', date)\n",
    "#     resampled.insert(1, 'attraction', attraction)\n",
    "\n",
    "#     # Append to final list\n",
    "#     groups3.append(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_netjes_3 = pd.concat(groups3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_netjes_3.to_csv('dataset_Disney_clean_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(0, 176, 240, 1); color: rgba(255, 255, 255, 1); font-size: 24px; font-weight: bold; padding: 10px; border-radius: 15px;\">\n",
    "    Interpolating and preparing training dataframe\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77543/77543 [13:55<00:00, 92.84it/s]  \n"
     ]
    }
   ],
   "source": [
    "groups_itp = list()\n",
    "\n",
    "for (date, attraction), group in tqdm(df_wait.groupby(['date', 'attraction'])):\n",
    "    # Time shift by 3 hours\n",
    "    time_shifted = group['datetime'] - datetime.timedelta(hours=3)\n",
    "    group['minute'] = 3 * 60 + time_shifted.dt.hour * 60 + time_shifted.dt.minute\n",
    "\n",
    "    # Ensure the required columns exist before proceeding\n",
    "    if not {'SACTMIN', 'SPOSTMIN'}.issubset(group.columns):\n",
    "        print(f\"Skipping {date} - {attraction}: Missing columns\")\n",
    "        continue  # Skip this iteration if columns are missing\n",
    "\n",
    "    # Drop unnecessary columns and compute the mean for duplicate minutes\n",
    "    group = group.drop(columns=['datetime', 'attraction', 'date'], errors='ignore')  # Avoid KeyError\n",
    "    group = group.groupby('minute', as_index=False)[['SACTMIN', 'SPOSTMIN']].mean()\n",
    "\n",
    "    # Define the new index (0 to 1620 minutes in 30-minute intervals)\n",
    "    new_index = np.arange(0, 27 * 60 + 1, 30)\n",
    "\n",
    "    # Set 'minute' as the index and reindex with interpolation\n",
    "    group = group.set_index('minute')\n",
    "    reindexed = group.reindex(np.unique(np.concatenate([new_index, group.index]))).interpolate(method='linear')\n",
    "\n",
    "    # Keep only the required time indices\n",
    "    resampled = reindexed.loc[new_index].reset_index()\n",
    "\n",
    "    # Round to nearest 5-minute interval\n",
    "    for col in ['SACTMIN', 'SPOSTMIN']:\n",
    "        if col in resampled.columns:\n",
    "            resampled[col] = ((resampled[col] + 2.5) // 5) * 5\n",
    "    \n",
    "    # Interpolate SPOSTMIN to fill blanks\n",
    "    resampled['SPOSTMIN_interp'] = resampled['SPOSTMIN'].interpolate(method='linear')\n",
    "\n",
    "    # Calculate the actual over posted ratio\n",
    "    resampled['actual_over_posted'] =  resampled['SACTMIN'] / resampled['SPOSTMIN_interp']\n",
    "\n",
    "    # Insert date and attraction columns\n",
    "    resampled.insert(0, 'date', date)\n",
    "    resampled.insert(1, 'attraction', attraction)\n",
    "\n",
    "    # Append to final list\n",
    "    groups_itp.append(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netjes_itp = pd.concat(groups_itp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>attraction</th>\n",
       "      <th>minute</th>\n",
       "      <th>SACTMIN</th>\n",
       "      <th>SPOSTMIN</th>\n",
       "      <th>SPOSTMIN_interp</th>\n",
       "      <th>actual_over_posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>7_dwarfs_train</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>7_dwarfs_train</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>7_dwarfs_train</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>7_dwarfs_train</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>7_dwarfs_train</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264860</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>winnie_the_pooh</td>\n",
       "      <td>1500</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264861</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>winnie_the_pooh</td>\n",
       "      <td>1530</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264862</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>winnie_the_pooh</td>\n",
       "      <td>1560</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264863</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>winnie_the_pooh</td>\n",
       "      <td>1590</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264864</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>winnie_the_pooh</td>\n",
       "      <td>1620</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4264865 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date       attraction  minute  SACTMIN  SPOSTMIN  \\\n",
       "0       2015-01-01   7_dwarfs_train       0      NaN       NaN   \n",
       "1       2015-01-01   7_dwarfs_train      30      NaN       NaN   \n",
       "2       2015-01-01   7_dwarfs_train      60      NaN       NaN   \n",
       "3       2015-01-01   7_dwarfs_train      90      NaN       NaN   \n",
       "4       2015-01-01   7_dwarfs_train     120      NaN       NaN   \n",
       "...            ...              ...     ...      ...       ...   \n",
       "4264860 2021-12-28  winnie_the_pooh    1500     15.0       5.0   \n",
       "4264861 2021-12-28  winnie_the_pooh    1530     15.0       5.0   \n",
       "4264862 2021-12-28  winnie_the_pooh    1560     15.0       5.0   \n",
       "4264863 2021-12-28  winnie_the_pooh    1590     15.0       5.0   \n",
       "4264864 2021-12-28  winnie_the_pooh    1620     15.0       5.0   \n",
       "\n",
       "         SPOSTMIN_interp  actual_over_posted  \n",
       "0                    NaN                 NaN  \n",
       "1                    NaN                 NaN  \n",
       "2                    NaN                 NaN  \n",
       "3                    NaN                 NaN  \n",
       "4                    NaN                 NaN  \n",
       "...                  ...                 ...  \n",
       "4264860              5.0                 3.0  \n",
       "4264861              5.0                 3.0  \n",
       "4264862              5.0                 3.0  \n",
       "4264863              5.0                 3.0  \n",
       "4264864              5.0                 3.0  \n",
       "\n",
       "[4264865 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_netjes_itp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the full cleaned and interpolated dataset to csv\n",
    "df_netjes_itp.to_csv(\"../data/clean/waiting_times_interpolated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dataset for training our prediction model and save it to csv\n",
    "# Drop unnecessary columns and rows without actual_over_posted ratio\n",
    "training_dataset = df_netjes_itp.drop(columns=['SACTMIN', 'SPOSTMIN', 'SPOSTMIN_interp']).dropna(subset=['actual_over_posted'])\n",
    "\n",
    "training_dataset.to_csv(\"../data/clean/training_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
